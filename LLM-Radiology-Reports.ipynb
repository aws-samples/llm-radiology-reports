{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ef4cb5-fb73-4f69-884b-23e20cc7f23b",
   "metadata": {},
   "source": [
    "# Generating Radiology Report Impression with Large Language Model on AWS\n",
    "### Fine-Tuning State-of-the-Art LLMs (Flan-T5 XL) to generate impressions from findings in radiology reports\n",
    "\n",
    "We focus on demonstrating strategy on fine tuning third party pretrained large language models (LLM) for the task of radiology report summarization leveraging AWS services. LLM have demonstrated remarkable capabilities in natural language understanding and generation, serving as foundation models that can be adapted to various domains and tasks. We fine-tuned the Flan-T5 XL model for summarization task on 91544 free-text radiology reports obtained from MIMIC-CXR dataset. We also presented evaluation with using the pretrained model out of the box. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc3440-b4b7-48ea-a178-4375c8fca35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install nest-asyncio==1.5.5 --quiet\n",
    "!pip install ipywidgets==8.0.4 --quiet\n",
    "!pip install sagemaker==2.148.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad0b60-f50f-450b-99e8-1fe1b0737b49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# Get current region, role, and default bucket\n",
    "aws_region = boto3.Session().region_name\n",
    "aws_role = sagemaker.session.Session().get_caller_identity_arn()\n",
    "output_bucket = 'llm-radiology-bucket'\n",
    "\n",
    "# This will be useful for printing\n",
    "newline, bold, unbold = \"\\n\", \"\\033[1m\", \"\\033[0m\"\n",
    "\n",
    "print(f\"{bold}aws_region:{unbold} {aws_region}\")\n",
    "print(f\"{bold}aws_role:{unbold} {aws_role}\")\n",
    "print(f\"{bold}output_bucket:{unbold} {output_bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8bd988-dd97-4c2c-8f68-ebdfacdf8850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "from ipywidgets import Dropdown\n",
    "from sagemaker.jumpstart.filters import And\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "# Default model choice\n",
    "model_id = \"huggingface-text2text-flan-t5-xl\"\n",
    "\n",
    "# Identify FLAN T5 models that support fine-tuning\n",
    "filter_value = And(\"task == text2text\", \"framework == huggingface\", \"training_supported == true\")\n",
    "model_list = [m for m in list_jumpstart_models(filter=filter_value) if \"flan-t5\" in m]\n",
    "\n",
    "# Display the model IDs in a dropdown, for user to select\n",
    "dropdown = Dropdown(\n",
    "    value=model_id,\n",
    "    options=model_list,\n",
    "    description=\"FLAN T5 models available for fine-tuning:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")\n",
    "display(IPython.display.Markdown(\"### Select a pre-trained model from the dropdown below\"))\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7bb972-2619-4601-be9b-4203b1dbdab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.instance_types import retrieve_default\n",
    "\n",
    "model_id, model_version = dropdown.value, \"*\"\n",
    "\n",
    "# Instance types for training and inference\n",
    "training_instance_type = retrieve_default(\n",
    "    model_id=model_id, model_version=model_version, scope=\"training\"\n",
    ")\n",
    "inference_instance_type = retrieve_default(\n",
    "    model_id=model_id, model_version=model_version, scope=\"inference\"\n",
    ")\n",
    "\n",
    "print(f\"{bold}model_id:{unbold} {model_id}\")\n",
    "print(f\"{bold}training_instance_type:{unbold} {training_instance_type}\")\n",
    "print(f\"{bold}inference_instance_type:{unbold} {inference_instance_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0b8f62-7e90-4cab-b8e2-df362a1f4eab",
   "metadata": {},
   "source": [
    "### Prepare Training Data in JSONL Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20ba75-0dd5-44e1-8cce-4cf6479d0b91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_json('train.json')\n",
    "\n",
    "#dev1 is the evaluation dataset from the MIMIC CXR dataset\n",
    "dev1 = pd.read_json('dev.json')\n",
    "\n",
    "#dev2 is the evaluation dataset from Indiana University\n",
    "dev2 = pd.read_json('indiana_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77faca9f-2fce-43a3-a695-314f91ff8392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Rename the columns to prompt and completion\n",
    "train_df = train_df[['findings', 'impression']].rename(columns={'findings': 'prompt', 'impression': 'completion'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c0ae9-7b45-41e8-b47c-ab0762a837f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to json lines format\n",
    "train_df.to_json('train.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60ec03-db9d-44cc-a9f7-d248a26c826f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_data_file = \"train.jsonl\" \n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "train_data_location = f\"s3://{output_bucket}/train_data\"\n",
    "S3Uploader.upload(local_data_file, train_data_location)\n",
    "print(f\"{bold}training data:{unbold} {train_data_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1234ac-47b1-4e86-baf3-581dae637ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "# Training instance will use this image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Pre-trained model\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"training\"\n",
    ")\n",
    "\n",
    "# Script to execute on the training instance\n",
    "train_script_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"training\"\n",
    ")\n",
    "\n",
    "output_location = f\"s3://{output_bucket}/demo-llm-rad-fine-tune-flan-t5/\"\n",
    "\n",
    "print(f\"{bold}image uri:{unbold} {train_image_uri}\")\n",
    "print(f\"{bold}model uri:{unbold} {train_model_uri}\")\n",
    "print(f\"{bold}script uri:{unbold} {train_script_uri}\")\n",
    "print(f\"{bold}output location:{unbold} {output_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8d751-0c59-4302-802d-e03f53d9c2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "\n",
    "# We will override some default hyperparameters with custom values\n",
    "hyperparameters[\"epochs\"] = \"3\"\n",
    "print(hyperparameters)\n",
    "\n",
    "# Note that the maximum output length is set to 128 tokens by default.\n",
    "# The targets in your data (i.e., ground truth responses) will be truncated to this size.\n",
    "# You can override this behavior, e.g.,\n",
    "# hyperparameters[\"max_output_length\"] = \"256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6523c4b-a8d9-4fc4-9334-c2a6e1bad457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "model_name = \"-\".join(model_id.split(\"-\")[2:])  # get the most informative part of ID\n",
    "training_job_name = name_from_base(f\"js-demo-{model_name}-{hyperparameters['epochs']}\")\n",
    "print(f\"{bold}job name:{unbold} {training_job_name}\")\n",
    "\n",
    "training_metric_definitions = [\n",
    "    {\"Name\": \"val_loss\", \"Regex\": \"'eval_loss': ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"'loss': ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"'epoch': ([0-9\\\\.]+)\"},\n",
    "]\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "sm_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    source_dir=train_script_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    volume_size=300,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=output_location,\n",
    "    metric_definitions=training_metric_definitions,\n",
    ")\n",
    "\n",
    "# Launch a SageMaker training job over data located in the given S3 path\n",
    "# Training jobs can take hours, it is recommended to set wait=False,\n",
    "# and monitor job status through SageMaker console\n",
    "sm_estimator.fit({\"training\": train_data_location}, job_name=training_job_name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49537189-7c5f-4563-b774-48f3ec96fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import TrainingJobAnalytics\n",
    "\n",
    "# Wait for a couple of minutes for the job to start before running this cell\n",
    "# This can be called while the job is still running\n",
    "df = TrainingJobAnalytics(training_job_name=training_job_name).dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3322e8-779e-453f-86ef-ccc5b9ee71b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a197a-c7bf-443c-a2fd-0820c965fac1",
   "metadata": {},
   "source": [
    "## Deploy Inference Endpoints for Both Original Pretrained and Finetuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d301b6-59ba-4bdc-ae5e-2eeab597e6f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "# Retrieve the inference docker image URI. This is the base HuggingFace container image\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=aws_region,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    image_scope=\"inference\",\n",
    "    instance_type=inference_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562d2b5-b3b9-44a8-956a-3307cb914825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import model_uris, script_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "# Retrieve the URI of the pre-trained model\n",
    "pre_trained_model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "large_model_env = {\"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\", \"TS_DEFAULT_WORKERS_PER_MODEL\": \"1\"}\n",
    "\n",
    "pre_trained_name = name_from_base(f\"jumpstart-demo-pre-trained-{model_id}\")\n",
    "\n",
    "# Create the SageMaker model instance of the pre-trained model\n",
    "if (\"small\" in model_id) or (\"base\" in model_id):\n",
    "    deploy_source_uri = script_uris.retrieve(\n",
    "        model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    "    )\n",
    "    pre_trained_model = Model(\n",
    "        image_uri=deploy_image_uri,\n",
    "        source_dir=deploy_source_uri,\n",
    "        entry_point=\"inference.py\",\n",
    "        model_data=pre_trained_model_uri,\n",
    "        role=aws_role,\n",
    "        predictor_cls=Predictor,\n",
    "        name=pre_trained_name,\n",
    "    )\n",
    "else:\n",
    "    # For those large models, we already repack the inference script and model\n",
    "    # artifacts for you, so the `source_dir` argument to Model is not required.\n",
    "    pre_trained_model = Model(\n",
    "        image_uri=deploy_image_uri,\n",
    "        model_data=pre_trained_model_uri,\n",
    "        role=aws_role,\n",
    "        predictor_cls=Predictor,\n",
    "        name=pre_trained_name,\n",
    "        env=large_model_env,\n",
    "    )\n",
    "\n",
    "print(f\"{bold}image URI:{unbold}{newline} {deploy_image_uri}\")\n",
    "print(f\"{bold}model URI:{unbold}{newline} {pre_trained_model_uri}\")\n",
    "print(\"Deploying an endpoint ...\")\n",
    "\n",
    "# Deploy the pre-trained model. Note that we need to pass Predictor class when we deploy model\n",
    "# through Model class, for being able to run inference through the SageMaker API\n",
    "pre_trained_predictor = pre_trained_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=pre_trained_name,\n",
    ")\n",
    "print(f\"{newline}Deployed an endpoint {pre_trained_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bb31c-d5c4-4764-8e8b-231db88bc009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "fine_tuned_name = name_from_base(f\"jumpstart-demo-fine-tuned-{model_id}\")\n",
    "fine_tuned_model_uri = f\"{output_location}{training_job_name}/output/model.tar.gz\"\n",
    "\n",
    "# Create the SageMaker model instance of the fine-tuned model\n",
    "fine_tuned_model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    model_data=fine_tuned_model_uri,\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=fine_tuned_name,\n",
    "    env=large_model_env,\n",
    ")\n",
    "\n",
    "print(f\"{bold}image URI:{unbold}{newline} {deploy_image_uri}\")\n",
    "print(f\"{bold}model URI:{unbold}{newline} {fine_tuned_model_uri}\")\n",
    "print(\"Deploying an endpoint ...\")\n",
    "\n",
    "# Deploy the fine-tuned model.\n",
    "fine_tuned_predictor = fine_tuned_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=fine_tuned_name,\n",
    ")\n",
    "print(f\"{newline}Deployed an endpoint {fine_tuned_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6034ff-10a6-4c69-9f81-0f8cd524da72",
   "metadata": {},
   "source": [
    "### Preprocess Evaluation Dataset and Run inference queries\n",
    "As the name suggests, a Text2Text model such as FLAN T5 receives a piece of text as input, and generates text as output. The input text will contain the description of the task. In this demo, our task is to generate impressions given a piece of text/findings. The impressions must be relevant to the findings, but the findings should contain no answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e196c-b292-4413-b183-6441305610f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d68351-9402-4687-9e8f-d4461cbb60d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Generate radiology report impressions based on the following findings. Findings: {context}\"\n",
    "\n",
    "#Input sample paragraphs from dev1 evaluation set (MIMIC CXR findings)\n",
    "\n",
    "test_paragraphs_dev1 = [\n",
    "    \"\"\"\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b10ff-df0b-4ef9-917d-16b6e62d380e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Parameters of (output) text generation. A great introduction to generation\n",
    "# parameters can be found at https://huggingface.co/blog/how-to-generate\n",
    "parameters = {\n",
    "    \"max_length\": 80,  # restrict the length of the generated text\n",
    "    \"num_return_sequences\": 1,  # we will inspect several model outputs\n",
    "    \"num_beams\": 10,  # use beam search\n",
    "}\n",
    "\n",
    "\n",
    "# Helper functions for running inference queries\n",
    "def query_endpoint_with_json_payload(payload, endpoint_name):\n",
    "    encoded_json = json.dumps(payload).encode(\"utf-8\")\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, ContentType=\"application/json\", Body=encoded_json\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response_multiple_texts(query_response):\n",
    "    model_predictions = json.loads(response[\"Body\"].read())\n",
    "    generated_text = model_predictions['generated_texts']\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "def generate_impressions(endpoint_name, text):\n",
    "    expanded_prompt = prompt.replace(\"{context}\", text)\n",
    "    payload = {\"text_inputs\": expanded_prompt, **parameters}\n",
    "    query_response = query_endpoint_with_json_payload(payload, endpoint_name=endpoint_name)\n",
    "    generated_texts = parse_response_multiple_texts(query_response)\n",
    "    for i, generated_text in enumerate(generated_texts):\n",
    "        print(f\"Response {i}: {generated_text}{newline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454942c2-4141-496f-a522-205d2ba07bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{bold}Prompt:{unbold} {repr(prompt)}\")\n",
    "for paragraph in test_paragraphs_dev1:\n",
    "    print(\"-\" * 80)\n",
    "    print(paragraph)\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{bold}pre-trained{unbold}\")\n",
    "    generate_impressions(pre_trained_name, paragraph)\n",
    "    print(f\"{bold}fine-tuned{unbold}\")\n",
    "    generate_impressions(fine_tuned_name, paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ef959-faa9-47e7-b395-80847673ea30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Generate radiology report impressions based on the following findings. Findings: {context}\"\n",
    "\n",
    "# Sources: Indiana University Radiology Findings\n",
    "test_paragraphs_dev2 = [\n",
    "    \"\"\"\n",
    "    The heart is normal in size and contour. There is no mediastinal widening. Low lung volumes. No focal airspace disease. No large pleural effusion or pneumothorax. The ____ are intact.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    The cardiomediastinal silhouette is within normal limits for appearance. No focal areas of pulmonary consolidation. No pneumothorax. No pleural effusion. The thoracic spine appears intact. No acute, displaced rib fractures.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    The cardiac and mediastinal contours are within normal limits. There are calcifications of the aortic ____. The lungs are hyperinflated with increased retrosternal airspace and flattening of hemidiaphragms. There is haziness in the right lung apex. There is a 1.7 cm nodular density in the medial right lung base seen on the frontal view, not identified on the lateral view. This may represent a vessel on end. There is no consolidation, pneumothorax, or effusion. There are mild degenerative changes of the spine.\n",
    "    \"\"\"\n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d85b5-82c2-4824-a64d-29d913fbaa34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"{bold}Prompt:{unbold} {repr(prompt)}\")\n",
    "for paragraph in test_paragraphs_dev2:\n",
    "    print(\"-\" * 80)\n",
    "    print(paragraph)\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{bold}pre-trained{unbold}\")\n",
    "    generate_impressions(pre_trained_name, paragraph)\n",
    "    print(f\"{bold}fine-tuned{unbold}\")\n",
    "    generate_impressions(fine_tuned_name, paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4ba39-0753-47fb-8525-b3cb57a574f0",
   "metadata": {},
   "source": [
    "## Model Evaluation and ROUGE Score Computation\n",
    "\n",
    "Compute ROUGE score for both pretrained and finetuned deployed models using dev1 and dev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5073234-e9ea-4970-8e10-dcc67e86702b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_impressions(endpoint_name, text):\n",
    "    expanded_prompt = prompt.replace(\"{context}\", text)\n",
    "    payload = {\"text_inputs\": expanded_prompt, **parameters}\n",
    "    query_response = query_endpoint_with_json_payload(payload, endpoint_name=endpoint_name)\n",
    "    generated_texts = parse_response_multiple_texts(query_response)\n",
    "    for i, generated_text in enumerate(generated_texts):\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a8da2-4a8f-404e-84cb-e54357d8169d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev1_sentences = dev1[\"findings\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27bab4-7e3b-4a73-ac7e-01e45dfab9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate impressions for dev1 using finetuned and pretrained models\n",
    "pred_dev1_pretrained = []\n",
    "pred_dev1_finetuned = []\n",
    "for paragraph in dev1_sentences:\n",
    "    dev1_pretrained = generate_impressions(pre_trained_name, paragraph)\n",
    "    dev1_finetuned = generate_impressions(fine_tuned_name, paragraph)\n",
    "    pred_dev1_pretrained.append(dev1_pretrained)\n",
    "    pred_dev1_finetuned.append(dev1_finetuned)\n",
    "    pred_dev1_pretrained_df = pd.DataFrame(pred_dev1_pretrained)\n",
    "    pred_dev1_finetuned_df = pd.DataFrame(pred_dev1_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57beb3b-a624-45a4-828b-ea0f12dd664e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev1[\"impression_pretrained\"] = pred_dev1_pretrained_df\n",
    "dev1[\"impression_finetuned\"] = pred_dev1_finetuned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84e417-35ee-4f9e-9463-3d3ea7b5c5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3765f-e1f4-4804-8bc7-f308f8ff6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute dev1 rouge score for finetuned and pretrained models\n",
    "\n",
    "import evaluate\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "#from transformers import AutoTokenizer, BartTokenizer\n",
    "\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\") #\"/home/hd/hd_hd/hd_rk435/evaluate/metrics/rouge\")\n",
    "#tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "result_pretrained_dev1 = rouge_score.compute(predictions=list(dev1[\"impression_pretrained\"]), references=list(dev1[\"impression\"]), use_aggregator=True) #, use_stemmer=True) #, tokenizer=tokenizer)\n",
    "print(\"ROUGE Score for Pretrained Flan-T5 XL model on Dev1 Set:\")\n",
    "print(result_pretrained_dev1)\n",
    "\n",
    "results_finetuned_dev1 = rouge_score.compute(predictions=list(dev1[\"impression_finetuned\"]),references=list(dev1[\"impression\"]), use_aggregator=True) #, use_stemmer=True) #, tokenizer=tokenizer)\n",
    "print(\"ROUGE Score for FineTuned Flan-T5 XL model on Dev1 Set:\")\n",
    "print(results_finetuned_dev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a14e1c-dd5c-4377-8377-6fa1d6930944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_pretrained_dev1_all = rouge_score.compute(predictions=list(dev1[\"impression_pretrained\"]),references=list(dev1[\"impression\"]), use_aggregator=False)\n",
    "results_pretrained_dev1_all_df = pd.DataFrame(results_pretrained_dev1_all)\n",
    "results_pretrained_dev1_all_df.plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11705148-e762-4acb-a5e2-155c6febb788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_pretrained_dev1_all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866570d-2e5d-44ad-8f36-cef4c1cbccee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_finetuned_dev1_all = rouge_score.compute(predictions=list(dev1[\"impression_finetuned\"]),references=list(dev1[\"impression\"]), use_aggregator=False)\n",
    "results_finetuned_dev1_all_df = pd.DataFrame(results_finetuned_dev1_all)\n",
    "results_finetuned_dev1_all_df.plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8d5b7-bf24-4eed-b8ab-52496b8c7a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_finetuned_dev1_all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae1aac-bf4b-4133-b708-a784a595f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2_sentences = dev2[\"findings\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e5078-5bb0-4e9a-ae71-2688dbaebc5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate impressions for dev2 using finetuned and pretrained models\n",
    "pred_dev2_pretrained = []\n",
    "pred_dev2_finetuned = []\n",
    "for paragraph in dev2_sentences:\n",
    "    dev2_pretrained = generate_impressions(pre_trained_name, paragraph)\n",
    "    dev2_finetuned = generate_impressions(fine_tuned_name, paragraph)\n",
    "    pred_dev2_pretrained.append(dev2_pretrained)\n",
    "    pred_dev2_finetuned.append(dev2_finetuned)\n",
    "    pred_dev2_pretrained_df = pd.DataFrame(pred_dev2_pretrained)\n",
    "    pred_dev2_finetuned_df = pd.DataFrame(pred_dev2_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a22fd-d3d2-4989-bb9e-9adb004974f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2[\"impression_pretrained\"] = pred_dev2_pretrained_df\n",
    "dev2[\"impression_finetuned\"] = pred_dev2_finetuned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd744f3-a622-4b55-9a86-ed116e6b5e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute dev2 rouge score for finetuned and pretrained models\n",
    "\n",
    "result_pretrained_dev2 = rouge_score.compute(predictions=list(dev2[\"impression_pretrained\"]), references=list(dev2[\"impression\"]), use_aggregator=True) #, use_stemmer=True) #, tokenizer=tokenizer)\n",
    "print(\"ROUGE Score for Pretrained Flan-T5 XL model on Dev2 (Indiana Uni) Set:\")\n",
    "print(result_pretrained_dev2)\n",
    "\n",
    "results_finetuned_dev2 = rouge_score.compute(predictions=list(dev2[\"impression_finetuned\"]),references=list(dev2[\"impression\"]), use_aggregator=True) #, use_stemmer=True) #, tokenizer=tokenizer)\n",
    "print(\"ROUGE Score for FineTuned Flan-T5 XL model Dev2 (Indiana Uni) Set:\")\n",
    "print(results_finetuned_dev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097bc54-034c-40a5-87be-55cae3a6bd22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_pretrained_dev2_all = rouge_score.compute(predictions=list(dev2[\"impression_pretrained\"]), references=list(dev2[\"impression\"]), use_aggregator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d55a8-ca65-4e8d-a61d-fc7e1c35460b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_pretrained_dev2_all_df = pd.DataFrame(result_pretrained_dev2_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c8aa4-6148-4403-a73c-752a0eb409b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_pretrained_dev2_all_df.plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ff2a4-9361-4d3a-960b-15e1c7a1c856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_finetuned_dev2_all = rouge_score.compute(predictions=list(dev2[\"impression_finetuned\"]),references=list(dev2[\"impression\"]), use_aggregator=False)\n",
    "results_finetuned_dev2_all_df = pd.DataFrame(results_finetuned_dev2_all)\n",
    "results_finetuned_dev2_all_df.plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0230e-68be-407c-b0a2-84d249b096fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_pretrained_dev2_all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef28b18-55a9-43bd-a942-8c362d755dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_finetuned_dev2_all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a451c2-7c35-466d-b4fe-fb7b1ad2a51e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev1 = dev1.join(results_finetuned_dev1_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d72c3f4-2c72-46ed-99bd-fb78a086ef3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev2 = dev2.join(results_finetuned_dev2_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c6c370-4885-49e8-b7ba-6431fdc404a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev1['data source'] = \"MIMIC CXR\"\n",
    "dev2['data source'] = \"Indiana Uni\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735c4a2-ccdc-425d-81d6-b3f5cff197bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([dev1, dev2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fec84-b2a9-478a-acc1-700d5021d94c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_radiology_pred = df[['findings', 'background', 'impression_finetuned', 'data source', 'rouge1', 'rouge2', 'rougeL']].rename(columns={'impression_finetuned': 'generated impressions'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d800f-7dff-45d0-a836-ff707c4ab55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"radiology_pred.json\" \n",
    "df_radiology_pred.to_json(file_name)\n",
    "\n",
    "# instantiate S3 client and upload to s3\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file(file_name, 'llm-radiology-bucket', 'prediction_data/radiology_pred.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979cde3-c71a-4e35-a2e1-51f8a3fd04a6",
   "metadata": {},
   "source": [
    "### Delete Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec548251-dfe0-4f45-ac3a-076bd5e0c445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete resources\n",
    "pre_trained_predictor.delete_model()\n",
    "pre_trained_predictor.delete_endpoint()\n",
    "fine_tuned_predictor.delete_model()\n",
    "fine_tuned_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522ec4c-f4c2-4416-8979-e568e73c89c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
